{"body": "<div class=\"section\" id=\"diffusion-imaging-in-python\">\n<span id=\"home\"></span><h1>Diffusion Imaging In Python<a class=\"headerlink\" href=\"#diffusion-imaging-in-python\" title=\"Permalink to this headline\">\u00b6</a></h1>\n<p><a class=\"reference external\" href=\"http://dipy.org\">Dipy</a> is a <strong>free</strong> and <strong>open source</strong> software project for computational neuroanatomy,\nfocusing mainly on <strong>diffusion</strong> <em>magnetic resonance imaging</em> (dMRI) analysis. It implements a\nbroad range of algorithms for denoising, registration, reconstruction, tracking, clustering,\nvisualization, and statistical analysis of MRI data.</p>\n<div class=\"section\" id=\"highlights\">\n<h2>Highlights<a class=\"headerlink\" href=\"#highlights\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p><strong>Dipy 0.11.0</strong> is now available. New features include:</p>\n<ul class=\"simple\">\n<li>New framework for contextual enhancement of ODFs.</li>\n<li>Compatibility with numpy (1.11).</li>\n<li>Compatibility with VTK 7.0 which supports Python 3.x.</li>\n<li>Faster PIESNO for noise estimation.</li>\n<li>Reorient gradient directions according to motion correction parameters.</li>\n<li>Supporting Python 3.3+ but not 3.2.</li>\n<li>Reduced memory usage in DTI.</li>\n<li>DSI now can use datasets with multiple b0s.</li>\n<li>Fixed different issues with Windows 64bit and Python 3.5.</li>\n</ul>\n<p><strong>Dipy 0.10.1</strong> is now available. New features in this release include:</p>\n<ul class=\"simple\">\n<li>Compatibility with new versions of scipy (0.16) and numpy (1.10).</li>\n<li>New cleaner visualization API, including compatibility with VTK 6, and functions to create your own interactive visualizations.</li>\n<li>Diffusion Kurtosis Imaging (DKI): Google Summer of Code work by Rafael Henriques.</li>\n<li>Mean Apparent Propagator (MAP) MRI for tissue microstructure estimation.</li>\n<li>Anisotropic Power Maps from spherical harmonic coefficients.</li>\n<li>A new framework for affine registration of images.</li>\n</ul>\n<p>See <a class=\"reference internal\" href=\"old_highlights/#old-highlights\"><span class=\"std std-ref\">older highlights</span></a>.</p>\n</div>\n<div class=\"section\" id=\"announcements\">\n<h2>Announcements<a class=\"headerlink\" href=\"#announcements\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<ul class=\"simple\">\n<li><a class=\"reference internal\" href=\"release0.11/#release0-11\"><span class=\"std std-ref\">Dipy 0.11</span></a> released February 21, 2016.</li>\n<li><a class=\"reference internal\" href=\"release0.10/#release0-10\"><span class=\"std std-ref\">Dipy 0.10</span></a> released December 4, 2015.</li>\n<li><a class=\"reference internal\" href=\"release0.9/#release0-9\"><span class=\"std std-ref\">Dipy 0.9.2</span></a> released, March 18, 2015.</li>\n<li><a class=\"reference internal\" href=\"release0.8/#release0-8\"><span class=\"std std-ref\">Dipy 0.8.0</span></a> released, January 6, 2015.</li>\n<li><a class=\"reference external\" href=\"http://dipy.org\">Dipy</a> was an official exhibitor in <a class=\"reference external\" href=\"http://ohbm.loni.usc.edu\">HBM 2015</a>.</li>\n<li>Dipy was featured in <a class=\"reference external\" href=\"http://www.the-scientist.com/?articles.view/articleNo/41266/title/White-s-the-Matter\">The Scientist Magazine</a>, Nov, 2014.</li>\n<li><a class=\"reference external\" href=\"http://www.frontiersin.org/Neuroinformatics/10.3389/fninf.2014.00008/abstract\">Dipy paper</a> accepted in Frontiers of Neuroinformatics, January 22nd, 2014.</li>\n</ul>\n<p>See some of our <a class=\"reference internal\" href=\"old_news/#old-news\"><span class=\"std std-ref\">past announcements</span></a></p>\n</div>\n<div class=\"section\" id=\"getting-started\">\n<h2>Getting Started<a class=\"headerlink\" href=\"#getting-started\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>Here is a simple example showing how to calculate <cite>color FA</cite>. We\nuse a single Tensor model to reconstruct the datasets which are saved in a\nNifti file along with the b-values and b-vectors which are saved as text files.\nIn this example we use only a few voxels with 101 gradient directions:</p>\n<div class=\"highlight-default\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">dipy.data</span> <span class=\"k\">import</span> <span class=\"n\">get_data</span>\n<span class=\"n\">fimg</span><span class=\"p\">,</span> <span class=\"n\">fbval</span><span class=\"p\">,</span> <span class=\"n\">fbvec</span> <span class=\"o\">=</span> <span class=\"n\">get_data</span><span class=\"p\">(</span><span class=\"s1\">&#39;small_101D&#39;</span><span class=\"p\">)</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">nibabel</span> <span class=\"k\">as</span> <span class=\"nn\">nib</span>\n<span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">nib</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">fimg</span><span class=\"p\">)</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">img</span><span class=\"o\">.</span><span class=\"n\">get_data</span><span class=\"p\">()</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">dipy.io</span> <span class=\"k\">import</span> <span class=\"n\">read_bvals_bvecs</span>\n<span class=\"n\">bvals</span><span class=\"p\">,</span> <span class=\"n\">bvecs</span> <span class=\"o\">=</span> <span class=\"n\">read_bvals_bvecs</span><span class=\"p\">(</span><span class=\"n\">fbval</span><span class=\"p\">,</span> <span class=\"n\">fbvec</span><span class=\"p\">)</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">dipy.core.gradients</span> <span class=\"k\">import</span> <span class=\"n\">gradient_table</span>\n<span class=\"n\">gtab</span> <span class=\"o\">=</span> <span class=\"n\">gradient_table</span><span class=\"p\">(</span><span class=\"n\">bvals</span><span class=\"p\">,</span> <span class=\"n\">bvecs</span><span class=\"p\">)</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">dipy.reconst.dti</span> <span class=\"k\">import</span> <span class=\"n\">TensorModel</span>\n<span class=\"n\">ten</span> <span class=\"o\">=</span> <span class=\"n\">TensorModel</span><span class=\"p\">(</span><span class=\"n\">gtab</span><span class=\"p\">)</span>\n<span class=\"n\">tenfit</span> <span class=\"o\">=</span> <span class=\"n\">ten</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">dipy.reconst.dti</span> <span class=\"k\">import</span> <span class=\"n\">fractional_anisotropy</span>\n<span class=\"n\">fa</span> <span class=\"o\">=</span> <span class=\"n\">fractional_anisotropy</span><span class=\"p\">(</span><span class=\"n\">tenfit</span><span class=\"o\">.</span><span class=\"n\">evals</span><span class=\"p\">)</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">dipy.reconst.dti</span> <span class=\"k\">import</span> <span class=\"n\">color_fa</span>\n<span class=\"n\">cfa</span> <span class=\"o\">=</span> <span class=\"n\">color_fa</span><span class=\"p\">(</span><span class=\"n\">fa</span><span class=\"p\">,</span> <span class=\"n\">tenfit</span><span class=\"o\">.</span><span class=\"n\">evecs</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>As an exercise try to calculate the <cite>color FA</cite> with your datasets. Here is what\na slice should look like.</p>\n<img alt=\"_images/colorfa.png\" class=\"align-center\" src=\"_images/colorfa.png\" />\n</div>\n<div class=\"section\" id=\"next-steps\">\n<h2>Next Steps<a class=\"headerlink\" href=\"#next-steps\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>You can learn more about how you to use <a class=\"reference external\" href=\"http://dipy.org\">Dipy</a> with  your datasets by reading the examples in our <a class=\"reference internal\" href=\"documentation/#documentation\"><span class=\"std std-ref\">Documentation</span></a>.</p>\n<div class=\"toctree-wrapper compound\">\n</div>\n</div>\n<div class=\"section\" id=\"support\">\n<h2>Support<a class=\"headerlink\" href=\"#support\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>We acknowledge support from the following organizations:</p>\n<ul class=\"simple\">\n<li>The Gordon and Betty Moore Foundation and the Alfred P. Sloan Foundation, through the\nUniversity of Washington eScience Institute Data Science Environment.</li>\n<li>Google supported the work of Rafael Neto Henriques and Julio Villalon through the Google\nSummer of Code Program, Summer 2015.</li>\n</ul>\n</div>\n</div>\n", "alabaster_version": "0.7.7", "display_toc": true, "title": "Diffusion Imaging In Python", "sourcename": "index.txt", "customsidebar": null, "metatags": "", "current_page_name": "index", "next": {"link": "documentation/", "title": "Documentation"}, "rellinks": [["genindex", "General Index", "I", "index"], ["np-modindex", "Python Module Index", "", "modules"], ["documentation", "Documentation", "N", "next"]], "meta": {}, "parents": [], "sidebars": null, "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">Diffusion Imaging In Python</a><ul>\n<li><a class=\"reference internal\" href=\"#highlights\">Highlights</a></li>\n<li><a class=\"reference internal\" href=\"#announcements\">Announcements</a></li>\n<li><a class=\"reference internal\" href=\"#getting-started\">Getting Started</a></li>\n<li><a class=\"reference internal\" href=\"#next-steps\">Next Steps</a></li>\n<li><a class=\"reference internal\" href=\"#support\">Support</a></li>\n</ul>\n</li>\n</ul>\n", "prev": null, "page_source_suffix": ".rst"}